
=== Parallel Configuration Summary ===
DP:                        2 
TP:                        2
SP:                        Disabled
PP:                        2
VP:                        None
CP:                        1
Activation Recomputation:  Disabled
Micro Batch Size:          1
Global Batch Size:         2
======================================

──────── Entering Experiment mistral_7b_pretraining with id: mistral_7b_pretraining_1761287219 ─────────
[06:27:00] INFO     Log directory is:                                             local_scheduler.py:777
                    /root/.nemo_run/experiments/mistral_7b_pretraining/mistral_7b                       
                    _pretraining_1761287219/mistral_7b_pretraining                                      
[06:27:00] Launching job mistral_7b_pretraining for experiment mistral_7b_pretraining  experiment.py:771
           INFO     Log directory is:                                             local_scheduler.py:777
                    /root/.nemo_run/experiments/mistral_7b_pretraining/mistral_7b                       
                    _pretraining_1761287219/mistral_7b_pretraining                                      
           INFO     Launched app:                                                        launcher.py:111
                    local_persistent://nemo_run/mistral_7b_pretraining-sccp3cxh3m2tq                    
────────────────── Waiting for Experiment mistral_7b_pretraining_1761287219 to finish ──────────────────

Experiment Status for mistral_7b_pretraining_1761287219

Task 0: mistral_7b_pretraining
- Status: RUNNING
- Executor: LocalExecutor
- Job id: mistral_7b_pretraining-sccp3cxh3m2tq
- Local Directory: /root/.nemo_run/experiments/mistral_7b_pretraining/mistral_7b_pretraining_1761287219/mistral_7b_pretraining

           INFO     Waiting for job mistral_7b_pretraining-sccp3cxh3m2tq to finish       launcher.py:131
                    [log=True]...                                                                       
retraining/0 I1024 06:27:02.198000 125732 torch/distributed/run.py:649] Using nproc_per_node=8.
retraining/0 W1024 06:27:02.199000 125732 torch/distributed/run.py:766] 
retraining/0 W1024 06:27:02.199000 125732 torch/distributed/run.py:766] *****************************************
retraining/0 W1024 06:27:02.199000 125732 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
retraining/0 W1024 06:27:02.199000 125732 torch/distributed/run.py:766] *****************************************
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195] Starting elastic_operator with launch configs:
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   entrypoint       : nemo_run.core.runners.fdl_runner
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   min_nodes        : 1
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   max_nodes        : 1
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   nproc_per_node   : 8
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   run_id           : 6763
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   rdzv_backend     : c10d
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   rdzv_endpoint    : localhost:0
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   rdzv_configs     : {'timeout': 900}
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   max_restarts     : 0
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   monitor_interval : 0.1
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   log_dir          : /root/.nemo_run/experiments/mistral_7b_pretraining/mistral_7b_pretraining_1761287219/mistral_7b_pretraining/nemo_run/mistral_7b_pretraining-sccp3cxh3m2tq/torchelastic/mistral_7b_pretraining
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195]   metrics_cfg      : {}
retraining/0 I1024 06:27:02.200000 125732 torch/distributed/launcher/api.py:195] 
retraining/0 I1024 06:27:02.203000 125732 torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python
retraining/0 I1024 06:27:02.204000 125732 torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   master_addr=cc76e080f006
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   master_port=41763
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:525] 
retraining/0 I1024 06:27:02.371000 125732 torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group
retraining/0 I1024 06:27:02.372000 125732 torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True
retraining/0 I1024 06:27:02.373000 125732 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
retraining/0 I1024 06:27:02.373000 125732 torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.
retraining/0 [default0]:[NeMo W 2025-10-24 06:27:18 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
retraining/0 [default0]:      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
retraining/0 [default0]:    
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /root/.cache/torch/megatron/megatron-gpt-345m_vocab,  merges_files: /root/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False
retraining/0 [default3]:[W1024 06:27:21.348732555 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default5]:[W1024 06:27:21.511996326 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Experiments will be logged at /root/baseline/scripts/nemo_experiments/default/2025-10-24_06-27-21
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has data parallel group : [0, 2]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 2]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 2], [1, 3], [4, 6], [5, 7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Ranks 0 has data parallel rank: 0
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has context parallel group: [0]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Ranks 0 has context parallel rank: 0
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has model parallel group: [0, 1, 4, 5]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All model parallel group ranks: [[0, 1, 4, 5], [2, 3, 6, 7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has tensor model parallel group: [0, 1]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All tensor model parallel group ranks: [[0, 1], [2, 3], [4, 5], [6, 7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has pipeline model parallel group: [0, 4]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has embedding group: [0, 4]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All pipeline model parallel group ranks: [[0, 4], [1, 5], [2, 6], [3, 7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] All embedding group ranks: [[0, 4], [1, 5], [2, 6], [3, 7]]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:21 nemo_logging:393] Rank 0 has embedding rank: 0
retraining/0 [default0]:GPU available: True (cuda), used: True
retraining/0 [default0]:TPU available: False, using: 0 TPU cores
retraining/0 [default0]:HPU available: False, using: 0 HPUs
retraining/0 [default0]:[NeMo W 2025-10-24 06:27:21 nemo_logging:405] "update_logger_directory" is True. Overwriting tensorboard logger "save_dir" to /root/baseline/scripts/nemo_experiments
retraining/0 [default0]:You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
retraining/0 [default0]:[W1024 06:27:21.018195219 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default0]:----------------------------------------------------------------------------------------------------
retraining/0 [default0]:distributed_backend=nccl
retraining/0 [default0]:All distributed processes registered. Starting with 8 processes
retraining/0 [default0]:----------------------------------------------------------------------------------------------------
retraining/0 [default0]:
retraining/0 [default5]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default5]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default5]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default7]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default7]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default7]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default7]:[W1024 06:27:22.542837565 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default3]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default3]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default3]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default1]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default1]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default1]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default6]:[W1024 06:27:22.884459011 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default1]:[W1024 06:27:22.861713796 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default6]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default6]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default6]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default0]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default0]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default0]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default2]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default2]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default2]:[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default4]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default4]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default4]:[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
retraining/0 [default4]:[W1024 06:27:23.158321667 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default2]:[W1024 06:27:23.175677167 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Let split_matrix = [(0, 0.9), (0.9, 0.9500000000000001), (0.9500000000000001, 1.0)]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Building GPTDataset splits with sizes=[40, 0, 2] and config=GPTDatasetConfig(random_seed=1234, sequence_length=8192, blend=[['/root/dataset/openwebtext'], None], blend_per_split=None, split='900,50,50', split_matrix=[(0, 0.9), (0.9, 0.9500000000000001), (0.9500000000000001, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.huggingface.auto_tokenizer.AutoTokenizer object at 0x7a83457c3a10>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Load the _IndexReader from /root/dataset/openwebtext.idx
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Extract the sequence lengths
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Extract the sequence pointers
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Extract the document indices
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] > total number of sequences: 8013769
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] > total number of documents: 8013769
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Load the GPTDataset train indices
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the document index from 2e5c432c96344d030e35c97808d0490f-GPTDataset-train-document_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the sample index from 2e5c432c96344d030e35c97808d0490f-GPTDataset-train-sample_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the shuffle index from 2e5c432c96344d030e35c97808d0490f-GPTDataset-train-shuffle_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] > total number of samples: 974208
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Load the GPTDataset valid indices
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the document index from 180546dee5d5a6d96e72125412370813-GPTDataset-valid-document_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the sample index from 180546dee5d5a6d96e72125412370813-GPTDataset-valid-sample_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the shuffle index from 180546dee5d5a6d96e72125412370813-GPTDataset-valid-shuffle_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] > total number of samples: 53956
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] Load the GPTDataset test indices
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the document index from 20c3035ad85ebfbc6307ec9b45c34983-GPTDataset-test-document_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the sample index from 20c3035ad85ebfbc6307ec9b45c34983-GPTDataset-test-sample_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] 	Load the shuffle index from 20c3035ad85ebfbc6307ec9b45c34983-GPTDataset-test-shuffle_index.npy
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 utils:661] > total number of samples: 54137
retraining/0 [default0]:[NeMo W 2025-10-24 06:27:24 nemo_logging:405] Recommend using CUDA_DEVICE_MAX_CONNECTIONS=1 for best performance                         but get None
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:24 nemo_logging:393] Padded vocab_size: 50432, original vocab_size: 50257, dummy tokens: 175.
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 nemo_logging:393] Copying Trainer's 'max_steps' (20) to LR scheduler's 'max_steps'.
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 num_microbatches_calculator:228] setting number of microbatches to constant 1
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1848246272
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 utils:661] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=True, overlap_param_gather=True, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=134217728, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, reuse_grad_buf_for_mxfp8_param_ag=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False, nccl_ub=False, fsdp_double_buffer=False)
retraining/0 [default4]:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 utils:682] Number of buckets for gradient all-reduce / reduce-scatter: 12
retraining/0 [default0]:    Params for bucket 1 (138420224 elements, 138420224 padded size):
retraining/0 [default0]:    	module.decoder.layers.15.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.15.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.14.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.15.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.15.self_attention.linear_proj.weight
retraining/0 [default0]:    Params for bucket 2 (167780352 elements, 167780352 padded size):
retraining/0 [default0]:    	module.decoder.layers.14.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.13.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.14.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.14.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.13.mlp.linear_fc1.weight
retraining/0 [default0]:    Params for bucket 3 (159399936 elements, 159399936 padded size):
retraining/0 [default0]:    	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.12.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.13.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.12.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.11.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.13.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.12.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.12.self_attention.linear_proj.weight
retraining/0 [default0]:    Params for bucket 4 (167780352 elements, 167780352 padded size):
retraining/0 [default0]:    	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.11.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.10.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.11.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.11.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.10.mlp.linear_fc1.weight
retraining/0 [default0]:    Params for bucket 5 (159399936 elements, 159399936 padded size):
retraining/0 [default0]:    	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.10.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.9.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.9.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.8.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.10.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.9.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.9.self_attention.linear_proj.weight
retraining/0 [default0]:    Params for bucket 6 (167780352 elements, 167780352 padded size):
retraining/0 [default0]:    	module.decoder.layers.8.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.7.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.8.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.8.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.7.mlp.linear_fc1.weight
retraining/0 [default0]:    Params for bucket 7 (159399936 elements, 159399936 padded size):
retraining/0 [default0]:    	module.decoder.layers.7.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.6.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.6.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.5.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.7.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.6.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.6.self_attention.linear_proj.weight
retraining/0 [default0]:    Params for bucket 8 (167780352 elements, 167780352 padded size):
retraining/0 [default0]:    	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.4.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.5.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.5.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.5.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.4.mlp.linear_fc1.weight
retraining/0 [default0]:    Params for bucket 9 (159399936 elements, 159399936 padded size):
retraining/0 [default0]:    	module.decoder.layers.4.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.3.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.3.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.2.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.4.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.3.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.3.self_attention.linear_proj.weight
retraining/0 [default0]:    Params for bucket 10 (167780352 elements, 167780352 padded size):
retraining/0 [default0]:    	module.decoder.layers.2.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.2.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.1.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.2.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.1.mlp.linear_fc2.weight
retraining/0 [default0]:    Params for bucket 11 (130039808 elements, 130039808 padded size):
retraining/0 [default0]:    	module.decoder.layers.0.mlp.linear_fc2.weight
retraining/0 [default0]:    	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.1.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.0.self_attention.linear_qkv.weight
retraining/0 [default0]:    	module.decoder.layers.0.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.1.self_attention.linear_proj.weight
retraining/0 [default0]:    	module.decoder.layers.0.mlp.linear_fc1.weight
retraining/0 [default0]:    	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
retraining/0 [default0]:    	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
retraining/0 [default0]:    Params for bucket 12 (103284736 elements, 103284736 padded size):
retraining/0 [default0]:    	module.embedding.word_embeddings.weight
retraining/0 [default0]:[NeMo I 2025-10-24 06:27:25 utils:661] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=9e-05, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp8_recipe='delayed', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-05, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')
retraining/0 [default6]:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default7]:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default5]:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
retraining/0 [default0]:
retraining/0 [default0]:  | Name   | Type | Params | Mode 
retraining/0 [default0]:----------------------------------------
retraining/0 [default0]:0 | module | DDP  | 1.8 B  | train
retraining/0 [default0]:----------------------------------------
retraining/0 [default0]:1.8 B     Trainable params
retraining/0 [default0]:0         Non-trainable params
retraining/0 [default0]:1.8 B     Total params
retraining/0 [default0]:7,392.985 Total estimated model params size (MB)
retraining/0 [default0]:329       Modules in train mode
retraining/0 [default0]:0         Modules in eval mode
retraining/0 [default0]:[NeMo W 2025-10-24 06:27:30 rerun_state_machine:1263] Implicit initialization of Rerun State Machine!
retraining/0 [default0]:[NeMo W 2025-10-24 06:27:30 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED
retraining/0 [default4]:[rank4]: Traceback (most recent call last):
retraining/0 [default4]:[rank4]:   File "<frozen runpy>", line 198, in _run_module_as_main
retraining/0 [default4]:[rank4]:   File "<frozen runpy>", line 88, in _run_code
retraining/0 [default4]:[rank4]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 72, in <module>
retraining/0 [default4]:[rank4]:     fdl_runner_app()
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 340, in __call__
retraining/0 [default4]:[rank4]:     raise e
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 323, in __call__
retraining/0 [default4]:[rank4]:     return get_command(self)(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1161, in __call__
retraining/0 [default4]:[rank4]:     return self.main(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 677, in main
retraining/0 [default4]:[rank4]:     return _main(
retraining/0 [default4]:[rank4]:            ^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 195, in _main
retraining/0 [default4]:[rank4]:     rv = self.invoke(ctx)
retraining/0 [default4]:[rank4]:          ^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1443, in invoke
retraining/0 [default4]:[rank4]:     return ctx.invoke(self.callback, **ctx.params)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 788, in invoke
retraining/0 [default4]:[rank4]:     return __callback(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 698, in wrapper
retraining/0 [default4]:[rank4]:     return callback(**use_params)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 68, in fdl_direct_run
retraining/0 [default4]:[rank4]:     fdl_fn()
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 181, in pretrain
retraining/0 [default4]:[rank4]:     return train(
retraining/0 [default4]:[rank4]:            ^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 136, in train
retraining/0 [default4]:[rank4]:     trainer.fit(model, data)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
retraining/0 [default4]:[rank4]:     call._call_and_handle_interrupt(
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
retraining/0 [default4]:[rank4]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
retraining/0 [default4]:[rank4]:     return function(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
retraining/0 [default4]:[rank4]:     self._run(model, ckpt_path=ckpt_path)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
retraining/0 [default4]:[rank4]:     results = self._run_stage()
retraining/0 [default4]:[rank4]:               ^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
retraining/0 [default4]:[rank4]:     self.fit_loop.run()
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
retraining/0 [default4]:[rank4]:     self.advance()
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
retraining/0 [default4]:[rank4]:     self.epoch_loop.run(self._data_fetcher)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
retraining/0 [default4]:[rank4]:     self.advance(data_fetcher)
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/pytorch/trainer.py", line 47, in advance
retraining/0 [default4]:[rank4]:     super().advance(data_fetcher)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
retraining/0 [default4]:[rank4]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
retraining/0 [default4]:[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
retraining/0 [default4]:[rank4]:     self._optimizer_step(batch_idx, closure)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
retraining/0 [default4]:[rank4]:     call._call_lightning_module_hook(
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
retraining/0 [default4]:[rank4]:     output = fn(*args, **kwargs)
retraining/0 [default4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
retraining/0 [default4]:[rank4]:     optimizer.step(closure=optimizer_closure)
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/optimizer.py", line 153, in step
retraining/0 [default4]:[rank4]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
retraining/0 [default4]:[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 792, in optimizer_step
retraining/0 [default4]:[rank4]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default4]:[rank4]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
retraining/0 [default4]:[rank4]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default4]:[rank4]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
retraining/0 [default4]:[rank4]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
retraining/0 [default4]:[rank4]:     return optimizer.step(closure=closure, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py", line 124, in wrapper
retraining/0 [default4]:[rank4]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/core/optim/mcore_optim.py", line 129, in step
retraining/0 [default4]:[rank4]:     loss = closure()
retraining/0 [default4]:[rank4]:            ^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
retraining/0 [default4]:[rank4]:     closure_result = closure()
retraining/0 [default4]:[rank4]:                      ^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
retraining/0 [default4]:[rank4]:     self._result = self.closure(*args, **kwargs)
retraining/0 [default4]:[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
retraining/0 [default4]:[rank4]:     return func(*args, **kwargs)
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
retraining/0 [default4]:[rank4]:     step_output = self._step_fn()
retraining/0 [default4]:[rank4]:                   ^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
retraining/0 [default4]:[rank4]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
retraining/0 [default4]:[rank4]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
retraining/0 [default4]:[rank4]:     output = fn(*args, **kwargs)
retraining/0 [default4]:[rank4]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 724, in training_step
retraining/0 [default4]:[rank4]:     out = self.model.training_step(dataloader_iter, *args, **kwargs)
retraining/0 [default4]:[rank4]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 335, in training_step
retraining/0 [default4]:[rank4]:     return self._step(
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 447, in _step
retraining/0 [default4]:[rank4]:     return self.forward(
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 297, in forward
retraining/0 [default4]:[rank4]:     microbatch_outputs = step()
retraining/0 [default4]:[rank4]:                          ^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 1225, in __call__
retraining/0 [default4]:[rank4]:     return self.forward_backward_func(
retraining/0 [default4]:[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default4]:[rank4]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 2043, in forward_backward_pipelining_without_interleaving
retraining/0 [default4]:[rank4]:     finish_embedding_wgrad_compute(config, embedding_module)
retraining/0 [default4]:[rank4]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 589, in finish_embedding_wgrad_compute
retraining/0 [default4]:[rank4]:     drain_embedding_wgrad_compute(
retraining/0 [default4]:[rank4]:   File "/opt/megatron-lm/megatron/core/utils.py", line 1028, in drain_embedding_wgrad_compute
retraining/0 [default4]:[rank4]:     wgrad_compute(all_gathered_input[drain_idx], grad_output, weight)
retraining/0 [default4]:[rank4]:                                      ^^^^^^^^^
retraining/0 [default4]:[rank4]: UnboundLocalError: cannot access local variable 'drain_idx' where it is not associated with a value
retraining/0 [default6]:[rank6]: Traceback (most recent call last):
retraining/0 [default6]:[rank6]:   File "<frozen runpy>", line 198, in _run_module_as_main
retraining/0 [default6]:[rank6]:   File "<frozen runpy>", line 88, in _run_code
retraining/0 [default6]:[rank6]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 72, in <module>
retraining/0 [default6]:[rank6]:     fdl_runner_app()
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 340, in __call__
retraining/0 [default6]:[rank6]:     raise e
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 323, in __call__
retraining/0 [default6]:[rank6]:     return get_command(self)(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1161, in __call__
retraining/0 [default6]:[rank6]:     return self.main(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 677, in main
retraining/0 [default6]:[rank6]:     return _main(
retraining/0 [default6]:[rank6]:            ^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 195, in _main
retraining/0 [default6]:[rank6]:     rv = self.invoke(ctx)
retraining/0 [default6]:[rank6]:          ^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1443, in invoke
retraining/0 [default6]:[rank6]:     return ctx.invoke(self.callback, **ctx.params)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 788, in invoke
retraining/0 [default6]:[rank6]:     return __callback(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 698, in wrapper
retraining/0 [default6]:[rank6]:     return callback(**use_params)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 68, in fdl_direct_run
retraining/0 [default6]:[rank6]:     fdl_fn()
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 181, in pretrain
retraining/0 [default6]:[rank6]:     return train(
retraining/0 [default6]:[rank6]:            ^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 136, in train
retraining/0 [default6]:[rank6]:     trainer.fit(model, data)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
retraining/0 [default6]:[rank6]:     call._call_and_handle_interrupt(
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
retraining/0 [default6]:[rank6]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
retraining/0 [default6]:[rank6]:     return function(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
retraining/0 [default6]:[rank6]:     self._run(model, ckpt_path=ckpt_path)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
retraining/0 [default6]:[rank6]:     results = self._run_stage()
retraining/0 [default6]:[rank6]:               ^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
retraining/0 [default6]:[rank6]:     self.fit_loop.run()
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
retraining/0 [default6]:[rank6]:     self.advance()
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
retraining/0 [default6]:[rank6]:     self.epoch_loop.run(self._data_fetcher)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
retraining/0 [default6]:[rank6]:     self.advance(data_fetcher)
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/pytorch/trainer.py", line 47, in advance
retraining/0 [default6]:[rank6]:     super().advance(data_fetcher)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
retraining/0 [default6]:[rank6]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
retraining/0 [default6]:[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
retraining/0 [default6]:[rank6]:     self._optimizer_step(batch_idx, closure)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
retraining/0 [default6]:[rank6]:     call._call_lightning_module_hook(
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
retraining/0 [default6]:[rank6]:     output = fn(*args, **kwargs)
retraining/0 [default6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
retraining/0 [default6]:[rank6]:     optimizer.step(closure=optimizer_closure)
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/optimizer.py", line 153, in step
retraining/0 [default6]:[rank6]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
retraining/0 [default6]:[rank6]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 792, in optimizer_step
retraining/0 [default6]:[rank6]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default6]:[rank6]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
retraining/0 [default6]:[rank6]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default6]:[rank6]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
retraining/0 [default6]:[rank6]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
retraining/0 [default6]:[rank6]:     return optimizer.step(closure=closure, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py", line 124, in wrapper
retraining/0 [default6]:[rank6]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/core/optim/mcore_optim.py", line 129, in step
retraining/0 [default6]:[rank6]:     loss = closure()
retraining/0 [default6]:[rank6]:            ^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
retraining/0 [default6]:[rank6]:     closure_result = closure()
retraining/0 [default6]:[rank6]:                      ^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
retraining/0 [default6]:[rank6]:     self._result = self.closure(*args, **kwargs)
retraining/0 [default6]:[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
retraining/0 [default6]:[rank6]:     return func(*args, **kwargs)
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
retraining/0 [default6]:[rank6]:     step_output = self._step_fn()
retraining/0 [default6]:[rank6]:                   ^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
retraining/0 [default6]:[rank6]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
retraining/0 [default6]:[rank6]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
retraining/0 [default6]:[rank6]:     output = fn(*args, **kwargs)
retraining/0 [default6]:[rank6]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 724, in training_step
retraining/0 [default6]:[rank6]:     out = self.model.training_step(dataloader_iter, *args, **kwargs)
retraining/0 [default6]:[rank6]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 335, in training_step
retraining/0 [default6]:[rank6]:     return self._step(
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 447, in _step
retraining/0 [default6]:[rank6]:     return self.forward(
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 297, in forward
retraining/0 [default6]:[rank6]:     microbatch_outputs = step()
retraining/0 [default6]:[rank6]:                          ^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 1225, in __call__
retraining/0 [default6]:[rank6]:     return self.forward_backward_func(
retraining/0 [default6]:[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default6]:[rank6]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 2043, in forward_backward_pipelining_without_interleaving
retraining/0 [default6]:[rank6]:     finish_embedding_wgrad_compute(config, embedding_module)
retraining/0 [default6]:[rank6]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 589, in finish_embedding_wgrad_compute
retraining/0 [default6]:[rank6]:     drain_embedding_wgrad_compute(
retraining/0 [default6]:[rank6]:   File "/opt/megatron-lm/megatron/core/utils.py", line 1028, in drain_embedding_wgrad_compute
retraining/0 [default6]:[rank6]:     wgrad_compute(all_gathered_input[drain_idx], grad_output, weight)
retraining/0 [default6]:[rank6]:                                      ^^^^^^^^^
retraining/0 [default6]:[rank6]: UnboundLocalError: cannot access local variable 'drain_idx' where it is not associated with a value
retraining/0 [default7]:[rank7]: Traceback (most recent call last):
retraining/0 [default7]:[rank7]:   File "<frozen runpy>", line 198, in _run_module_as_main
retraining/0 [default7]:[rank7]:   File "<frozen runpy>", line 88, in _run_code
retraining/0 [default7]:[rank7]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 72, in <module>
retraining/0 [default7]:[rank7]:     fdl_runner_app()
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 340, in __call__
retraining/0 [default7]:[rank7]:     raise e
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 323, in __call__
retraining/0 [default7]:[rank7]:     return get_command(self)(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1161, in __call__
retraining/0 [default7]:[rank7]:     return self.main(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 677, in main
retraining/0 [default7]:[rank7]:     return _main(
retraining/0 [default7]:[rank7]:            ^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 195, in _main
retraining/0 [default7]:[rank7]:     rv = self.invoke(ctx)
retraining/0 [default7]:[rank7]:          ^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1443, in invoke
retraining/0 [default7]:[rank7]:     return ctx.invoke(self.callback, **ctx.params)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 788, in invoke
retraining/0 [default7]:[rank7]:     return __callback(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 698, in wrapper
retraining/0 [default7]:[rank7]:     return callback(**use_params)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 68, in fdl_direct_run
retraining/0 [default7]:[rank7]:     fdl_fn()
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 181, in pretrain
retraining/0 [default7]:[rank7]:     return train(
retraining/0 [default7]:[rank7]:            ^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 136, in train
retraining/0 [default7]:[rank7]:     trainer.fit(model, data)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
retraining/0 [default7]:[rank7]:     call._call_and_handle_interrupt(
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
retraining/0 [default7]:[rank7]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
retraining/0 [default7]:[rank7]:     return function(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
retraining/0 [default7]:[rank7]:     self._run(model, ckpt_path=ckpt_path)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
retraining/0 [default7]:[rank7]:     results = self._run_stage()
retraining/0 [default7]:[rank7]:               ^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
retraining/0 [default7]:[rank7]:     self.fit_loop.run()
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
retraining/0 [default7]:[rank7]:     self.advance()
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
retraining/0 [default7]:[rank7]:     self.epoch_loop.run(self._data_fetcher)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
retraining/0 [default7]:[rank7]:     self.advance(data_fetcher)
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/pytorch/trainer.py", line 47, in advance
retraining/0 [default7]:[rank7]:     super().advance(data_fetcher)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
retraining/0 [default7]:[rank7]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
retraining/0 [default7]:[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
retraining/0 [default7]:[rank7]:     self._optimizer_step(batch_idx, closure)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
retraining/0 [default7]:[rank7]:     call._call_lightning_module_hook(
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
retraining/0 [default7]:[rank7]:     output = fn(*args, **kwargs)
retraining/0 [default7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
retraining/0 [default7]:[rank7]:     optimizer.step(closure=optimizer_closure)
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/optimizer.py", line 153, in step
retraining/0 [default7]:[rank7]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
retraining/0 [default7]:[rank7]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 792, in optimizer_step
retraining/0 [default7]:[rank7]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default7]:[rank7]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
retraining/0 [default7]:[rank7]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default7]:[rank7]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
retraining/0 [default7]:[rank7]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
retraining/0 [default7]:[rank7]:     return optimizer.step(closure=closure, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py", line 124, in wrapper
retraining/0 [default7]:[rank7]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/core/optim/mcore_optim.py", line 129, in step
retraining/0 [default7]:[rank7]:     loss = closure()
retraining/0 [default7]:[rank7]:            ^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
retraining/0 [default7]:[rank7]:     closure_result = closure()
retraining/0 [default7]:[rank7]:                      ^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
retraining/0 [default7]:[rank7]:     self._result = self.closure(*args, **kwargs)
retraining/0 [default7]:[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
retraining/0 [default7]:[rank7]:     return func(*args, **kwargs)
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
retraining/0 [default7]:[rank7]:     step_output = self._step_fn()
retraining/0 [default7]:[rank7]:                   ^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
retraining/0 [default7]:[rank7]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
retraining/0 [default7]:[rank7]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
retraining/0 [default7]:[rank7]:     output = fn(*args, **kwargs)
retraining/0 [default7]:[rank7]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 724, in training_step
retraining/0 [default7]:[rank7]:     out = self.model.training_step(dataloader_iter, *args, **kwargs)
retraining/0 [default7]:[rank7]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 335, in training_step
retraining/0 [default7]:[rank7]:     return self._step(
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 447, in _step
retraining/0 [default7]:[rank7]:     return self.forward(
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 297, in forward
retraining/0 [default7]:[rank7]:     microbatch_outputs = step()
retraining/0 [default7]:[rank7]:                          ^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 1225, in __call__
retraining/0 [default7]:[rank7]:     return self.forward_backward_func(
retraining/0 [default7]:[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default7]:[rank7]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 2043, in forward_backward_pipelining_without_interleaving
retraining/0 [default7]:[rank7]:     finish_embedding_wgrad_compute(config, embedding_module)
retraining/0 [default7]:[rank7]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 589, in finish_embedding_wgrad_compute
retraining/0 [default7]:[rank7]:     drain_embedding_wgrad_compute(
retraining/0 [default7]:[rank7]:   File "/opt/megatron-lm/megatron/core/utils.py", line 1028, in drain_embedding_wgrad_compute
retraining/0 [default7]:[rank7]:     wgrad_compute(all_gathered_input[drain_idx], grad_output, weight)
retraining/0 [default7]:[rank7]:                                      ^^^^^^^^^
retraining/0 [default7]:[rank7]: UnboundLocalError: cannot access local variable 'drain_idx' where it is not associated with a value
retraining/0 [default5]:[rank5]: Traceback (most recent call last):
retraining/0 [default5]:[rank5]:   File "<frozen runpy>", line 198, in _run_module_as_main
retraining/0 [default5]:[rank5]:   File "<frozen runpy>", line 88, in _run_code
retraining/0 [default5]:[rank5]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 72, in <module>
retraining/0 [default5]:[rank5]:     fdl_runner_app()
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 340, in __call__
retraining/0 [default5]:[rank5]:     raise e
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 323, in __call__
retraining/0 [default5]:[rank5]:     return get_command(self)(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1161, in __call__
retraining/0 [default5]:[rank5]:     return self.main(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 677, in main
retraining/0 [default5]:[rank5]:     return _main(
retraining/0 [default5]:[rank5]:            ^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/typer/core.py", line 195, in _main
retraining/0 [default5]:[rank5]:     rv = self.invoke(ctx)
retraining/0 [default5]:[rank5]:          ^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1443, in invoke
retraining/0 [default5]:[rank5]:     return ctx.invoke(self.callback, **ctx.params)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 788, in invoke
retraining/0 [default5]:[rank5]:     return __callback(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/typer/main.py", line 698, in wrapper
retraining/0 [default5]:[rank5]:     return callback(**use_params)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/Run/nemo_run/core/runners/fdl_runner.py", line 68, in fdl_direct_run
retraining/0 [default5]:[rank5]:     fdl_fn()
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 181, in pretrain
retraining/0 [default5]:[rank5]:     return train(
retraining/0 [default5]:[rank5]:            ^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/collections/llm/api.py", line 136, in train
retraining/0 [default5]:[rank5]:     trainer.fit(model, data)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
retraining/0 [default5]:[rank5]:     call._call_and_handle_interrupt(
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
retraining/0 [default5]:[rank5]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
retraining/0 [default5]:[rank5]:     return function(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
retraining/0 [default5]:[rank5]:     self._run(model, ckpt_path=ckpt_path)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
retraining/0 [default5]:[rank5]:     results = self._run_stage()
retraining/0 [default5]:[rank5]:               ^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
retraining/0 [default5]:[rank5]:     self.fit_loop.run()
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
retraining/0 [default5]:[rank5]:     self.advance()
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
retraining/0 [default5]:[rank5]:     self.epoch_loop.run(self._data_fetcher)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
retraining/0 [default5]:[rank5]:     self.advance(data_fetcher)
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/pytorch/trainer.py", line 47, in advance
retraining/0 [default5]:[rank5]:     super().advance(data_fetcher)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
retraining/0 [default5]:[rank5]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
retraining/0 [default5]:[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
retraining/0 [default5]:[rank5]:     self._optimizer_step(batch_idx, closure)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
retraining/0 [default5]:[rank5]:     call._call_lightning_module_hook(
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
retraining/0 [default5]:[rank5]:     output = fn(*args, **kwargs)
retraining/0 [default5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py", line 1306, in optimizer_step
retraining/0 [default5]:[rank5]:     optimizer.step(closure=optimizer_closure)
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/optimizer.py", line 153, in step
retraining/0 [default5]:[rank5]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
retraining/0 [default5]:[rank5]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 792, in optimizer_step
retraining/0 [default5]:[rank5]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default5]:[rank5]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
retraining/0 [default5]:[rank5]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
retraining/0 [default5]:[rank5]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py", line 238, in optimizer_step
retraining/0 [default5]:[rank5]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
retraining/0 [default5]:[rank5]:     return optimizer.step(closure=closure, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py", line 124, in wrapper
retraining/0 [default5]:[rank5]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/core/optim/mcore_optim.py", line 129, in step
retraining/0 [default5]:[rank5]:     loss = closure()
retraining/0 [default5]:[rank5]:            ^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
retraining/0 [default5]:[rank5]:     closure_result = closure()
retraining/0 [default5]:[rank5]:                      ^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
retraining/0 [default5]:[rank5]:     self._result = self.closure(*args, **kwargs)
retraining/0 [default5]:[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
retraining/0 [default5]:[rank5]:     return func(*args, **kwargs)
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
retraining/0 [default5]:[rank5]:     step_output = self._step_fn()
retraining/0 [default5]:[rank5]:                   ^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py", line 317, in _training_step
retraining/0 [default5]:[rank5]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
retraining/0 [default5]:[rank5]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py", line 319, in _call_strategy_hook
retraining/0 [default5]:[rank5]:     output = fn(*args, **kwargs)
retraining/0 [default5]:[rank5]:              ^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py", line 724, in training_step
retraining/0 [default5]:[rank5]:     out = self.model.training_step(dataloader_iter, *args, **kwargs)
retraining/0 [default5]:[rank5]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 335, in training_step
retraining/0 [default5]:[rank5]:     return self._step(
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 447, in _step
retraining/0 [default5]:[rank5]:     return self.forward(
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 297, in forward
retraining/0 [default5]:[rank5]:     microbatch_outputs = step()
retraining/0 [default5]:[rank5]:                          ^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/NeMo/nemo/lightning/megatron_parallel.py", line 1225, in __call__
retraining/0 [default5]:[rank5]:     return self.forward_backward_func(
retraining/0 [default5]:[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
retraining/0 [default5]:[rank5]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 2043, in forward_backward_pipelining_without_interleaving
retraining/0 [default5]:[rank5]:     finish_embedding_wgrad_compute(config, embedding_module)
retraining/0 [default5]:[rank5]:   File "/opt/megatron-lm/megatron/core/pipeline_parallel/schedules.py", line 589, in finish_embedding_wgrad_compute
retraining/0 [default5]:[rank5]:     drain_embedding_wgrad_compute(
retraining/0 [default5]:[rank5]:   File "/opt/megatron-lm/megatron/core/utils.py", line 1028, in drain_embedding_wgrad_compute
retraining/0 [default5]:[rank5]:     wgrad_compute(all_gathered_input[drain_idx], grad_output, weight)
retraining/0 [default5]:[rank5]:                                      ^^^^^^^^^
retraining/0 [default5]:[rank5]: UnboundLocalError: cannot access local variable 'drain_idx' where it is not associated with a value
